{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective-Function\" data-toc-modified-id=\"Objective-Function-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objective Function</a></span></li><li><span><a href=\"#Domain\" data-toc-modified-id=\"Domain-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Domain</a></span></li><li><span><a href=\"#Optimization-Algoruthm\" data-toc-modified-id=\"Optimization-Algoruthm-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Optimization Algoruthm</a></span></li><li><span><a href=\"#Results-History\" data-toc-modified-id=\"Results-History-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Results History</a></span></li><li><span><a href=\"#Example-of-Sampling-from-the-Fomain\" data-toc-modified-id=\"Example-of-Sampling-from-the-Fomain-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Example of Sampling from the Fomain</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:43:37.340054Z",
     "start_time": "2019-10-07T10:43:37.336150Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:45:18.248131Z",
     "start_time": "2019-10-07T10:45:18.242275Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\n",
    "from src.feature_extraction import *\n",
    "from src.util import *\n",
    "from src.const import *\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import csv\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from hyperopt import tpe, Trials, STATUS_OK, hp, fmin\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:43:55.811601Z",
     "start_time": "2019-10-07T10:43:55.415814Z"
    }
   },
   "outputs": [],
   "source": [
    "listing = pd.read_csv('../preprocessed_data/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:44:00.559837Z",
     "start_time": "2019-10-07T10:44:00.528182Z"
    }
   },
   "outputs": [],
   "source": [
    "price = pd.read_csv('../preprocessed_data/listings_price.csv', header=None, names=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:45:25.640035Z",
     "start_time": "2019-10-07T10:45:25.573666Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in CATEGORY_COLUMNS:\n",
    "    listing.loc[:, col] = listing.loc[:, col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:45:26.806037Z",
     "start_time": "2019-10-07T10:45:26.748453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (64613, 65)\n",
      "Test shape:  (16154, 65)\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(listing, price, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train shape: ', train_features.shape)\n",
    "print('Test shape: ', test_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T10:45:30.550361Z",
     "start_time": "2019-10-07T10:45:30.546456Z"
    }
   },
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:25.795090Z",
     "start_time": "2019-08-15T19:23:25.790211Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=50)\n",
    "\n",
    "# Training set\n",
    "train_set = lgb.Dataset(train_features, label = train_labels, categorical_feature=category_columns)\n",
    "test_set = lgb.Dataset(test_features, label = test_labels, categorical_feature=category_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:25.801923Z",
     "start_time": "2019-08-15T19:23:25.796066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 50, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = model.get_params()\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:25.807779Z",
     "start_time": "2019-08-15T19:23:25.803875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using early stopping to determine number of estimators.\n",
    "del hyperparameters['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:51.953316Z",
     "start_time": "2019-08-15T19:23:25.809732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\DL\\lib\\site-packages\\lightgbm\\basic.py:741: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    }
   ],
   "source": [
    "# Perform cross validation with early stopping\n",
    "cv_results = lgb.cv(hyperparameters, train_set,  num_boost_round = 10000, nfold = N_FOLDS, metrics = 'rmse', \n",
    "                    early_stopping_rounds = 100, verbose_eval = False, seed = 42, categorical_feature=category_columns,\n",
    "                    stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:51.960654Z",
     "start_time": "2019-08-15T19:23:51.955268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximium RMSE in cross validation was 0.38774 with std of 0.00894.\n",
      "The ideal number of iterations was 1117.\n"
     ]
    }
   ],
   "source": [
    "best = cv_results['rmse-mean'][-1]\n",
    "\n",
    "# Standard deviation of best score\n",
    "best_std = cv_results['rmse-stdv'][-1]\n",
    "\n",
    "print(f'The maximium RMSE in cross validation was {best:.5f} with std of {best_std:.5f}.')\n",
    "print(f'The ideal number of iterations was {len(cv_results[\"rmse-mean\"])}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:51.970414Z",
     "start_time": "2019-08-15T19:23:51.962606Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    rmse_rf = (mean_squared_error(y_test, y_test_pred))**0.5\n",
    "    r2score = r2_score(y_test, y_test_pred)\n",
    "    adj_r2 = 1 - (1 - r2score) * (X_test.shape[0] - 1) / (X_test.shape[0] - X_test.shape[1] - 1)\n",
    "    \n",
    "    print(f'RMSE test: {rmse_rf}')\n",
    "    print(f'R2 score test: {r2score}')\n",
    "    print(f'Adjusted R2 score test: {adj_r2}')\n",
    "    \n",
    "    return rmse_rf, r2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:23:57.337083Z",
     "start_time": "2019-08-15T19:23:51.972366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model has rmse 0.38737 and r2score 0.76405\n"
     ]
    }
   ],
   "source": [
    "# Optimal number of esimators found in cv\n",
    "model.n_estimators = len(cv_results['rmse-mean'])\n",
    "\n",
    "# Train and make predicions with model\n",
    "model.fit(train_features, train_labels)\n",
    "preds = model.predict(test_features)\n",
    "baseline_rmse = (mean_squared_error(test_labels, preds))**0.5\n",
    "r2score = r2_score(test_labels, preds)\n",
    "\n",
    "print(f'The baseline model has rmse {baseline_rmse:.5f} and r2score {r2score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objective Function: takes in an input (hyperparameters) and returns a score to minimize or maximize (the cross validation score)\n",
    "* Domain space: the range of input values (hyperparameters) to evaluate\n",
    "* Optimization Algorithm: the method used to construct the surrogate function and choose the next values to evaluate\n",
    "* Results: score, value pairs that the algorithm uses to build the surrogate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "\n",
    "* take a set of hyperparameter values and return the cv score on the training data\n",
    "* An objective function in Hyperopt must return either a single real value to minimize or a dictionary with a key \"loss\" with the score to minimize (and a key \"status\" indicating if the run was successful or not)\n",
    "\n",
    "### Domain\n",
    "* Space in hyperopt. In Hyperopt, and other Bayesian optimization frameworks, the domian is not a discrete grid but instead has probability distributions for each hyperparameter. For each hyperparameter, we will use the same limits as with the grid, but instead of being defined at each point, the domain represents probabilities for each hyperparameter.\n",
    "\n",
    "### Optimization Algoruthm\n",
    "\n",
    "* optimization algorithm is the method for constructing the surrogate function (probability model) and selecting the next set of hyperparameters to evaluate in the objective function. Either `random search` or `Tree Parzen Estimator`\n",
    "\n",
    "### Results History\n",
    "* objective function evaluations. \n",
    "    1. A `Trials` object that stores the dictionary returned from the objective function\n",
    "    2. Adding a line to a csv file every iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:26:08.613386Z",
     "start_time": "2019-08-16T10:26:08.605578Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\n",
    "    \"\"\"\n",
    "    # keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top levl keys\n",
    "    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "    hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples', 'max_depth']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round=10000, nfold=N_FOLDS,\n",
    "                        early_stopping_rounds=100, metrics='rmse', \n",
    "                        categorical_feature=category_columns,\n",
    "                        stratified=False, seed=50)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['rmse-mean'][-1]\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['rmse-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "    \n",
    "    # write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([best_score, hyperparameters, ITERATION, run_time, best_score])\n",
    "    of_connection.close()\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': best_score, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The gbm cannot use the nested dictionary so we need to set the boosting_type and subsample as top level keys.\n",
    "* Nested conditionals allow us to use a different set of hyperparameters depending on other hyperparameters. For example, we can explore different models with completely different sets of hyperparameters by using nested conditionals. The only requirement is that the first nested statement must be based on a choice hyperparameter (the choice could be the type of model).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:29:37.282858Z",
     "start_time": "2019-08-16T10:29:37.276028Z"
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type',\n",
    "                               [{'boosting_type': 'gbdt', 'subsample': hp.uniform(\n",
    "                                   'gbdt_subsample', 0.5, 1)},\n",
    "                                {'boosting_type': 'dart', 'subsample': hp.uniform(\n",
    "                                    'dart_subsample', 0.5, 1)},\n",
    "                                {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 255, 2),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 12, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "    \"device\" : \"gpu\",\n",
    "    \"gpu_platform_id\": 0,\n",
    "    \"gpu_device_id\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sampling from the Fomain\n",
    "\n",
    "Sample from the domain (using the conditional logic) to see the result of each draw. Every time we run this code, the results will change. (Again notice that we need to assign the top level keys to the keywords understood by the GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:29:38.129228Z",
     "start_time": "2019-08-16T10:29:38.122397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.7333425547622549,\n",
       " 'device': 'gpu',\n",
       " 'gpu_device_id': 0,\n",
       " 'gpu_platform_id': 0,\n",
       " 'is_unbalance': False,\n",
       " 'learning_rate': 0.2525576455996738,\n",
       " 'max_depth': 11.0,\n",
       " 'min_child_samples': 405.0,\n",
       " 'num_leaves': 238.0,\n",
       " 'reg_alpha': 0.17110537408961257,\n",
       " 'reg_lambda': 0.7190327316157817,\n",
       " 'subsample_for_bin': 220000.0,\n",
       " 'subsample': 0.6693263909171743}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:30:00.545125Z",
     "start_time": "2019-08-16T10:29:39.972546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation loss = 0.50813.\n",
      "The optimal number of estimators was 18.\n"
     ]
    }
   ],
   "source": [
    "# Create a new file and open a connection\n",
    "OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()\n",
    "\n",
    "# Test the objective function\n",
    "results = objective(sample(space))\n",
    "print('The cross validation loss = {:.5f}.'.format(results['loss']))\n",
    "print('The optimal number of estimators was {}.'.format(results['hyperparameters']['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:31:03.991961Z",
     "start_time": "2019-08-16T10:31:03.988948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the algorithm\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Trials` object will hold everything returned from the objective function in the `.results` attribute. . We can use this after the search is complete to inspect the results, but an easier method is to read in the csv file because that will already be in a dataframe.\n",
    "* `fmin` takes the four parts defined above as well as the maximum number of iterations `max_evals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:33:47.392874Z",
     "start_time": "2019-08-16T10:33:47.388949Z"
    }
   },
   "outputs": [],
   "source": [
    "# record results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T10:33:56.237655Z",
     "start_time": "2019-08-16T10:33:56.232791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a file and open a connection\n",
    "OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:08:49.809393Z",
     "start_time": "2019-08-16T10:36:06.467156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 5/5 [1:32:43<00:00, 1212.80s/it, best loss: 0.3824701385023954]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 0,\n",
       " 'colsample_by_tree': 0.6249276122183668,\n",
       " 'gbdt_subsample': 0.5020882484727693,\n",
       " 'is_unbalance': 0,\n",
       " 'learning_rate': 0.014146502081758888,\n",
       " 'max_depth': 11.0,\n",
       " 'min_child_samples': 95.0,\n",
       " 'num_leaves': 192.0,\n",
       " 'reg_alpha': 0.8564733637863978,\n",
       " 'reg_lambda': 0.17706302999644274,\n",
       " 'subsample_for_bin': 40000.0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:12:26.722607Z",
     "start_time": "2019-08-16T12:12:26.716753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3824701385023954,\n",
       "  'hyperparameters': {'boosting_type': 'gbdt',\n",
       "   'colsample_bytree': 0.6249276122183668,\n",
       "   'device': 'gpu',\n",
       "   'gpu_device_id': 0,\n",
       "   'gpu_platform_id': 0,\n",
       "   'is_unbalance': True,\n",
       "   'learning_rate': 0.014146502081758888,\n",
       "   'max_depth': 11,\n",
       "   'min_child_samples': 95,\n",
       "   'num_leaves': 192,\n",
       "   'reg_alpha': 0.8564733637863978,\n",
       "   'reg_lambda': 0.17706302999644274,\n",
       "   'subsample_for_bin': 40000,\n",
       "   'subsample': 0.5020882484727693,\n",
       "   'n_estimators': 3083},\n",
       "  'iteration': 1,\n",
       "  'train_time': 516.6685468639989,\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the trials with lowest loss first\n",
    "trials_dict = sorted(trials.results, key=lambda x: x['loss'])\n",
    "trials_dict[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:12:49.486084Z",
     "start_time": "2019-08-16T12:12:49.465566Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:27:46.575294Z",
     "start_time": "2019-08-16T12:27:46.568463Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(results, name):\n",
    "    \"\"\"Evaluate model on test data using hyperparameter\n",
    "       in results \n",
    "       \n",
    "       Returns:\n",
    "           hyp_df: dataframe of hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    new_results = results.copy()\n",
    "    # string to dictionary\n",
    "    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n",
    "    \n",
    "    # Sort with best values on top\n",
    "    new_results = new_results.sort_values('score', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # Print out cross validation high score\n",
    "    print(f\"The higest cross validation score from {name} was {new_results.loc[0, 'score']:.5f}\"\n",
    "          f\" found on iteration {new_results.loc[0, 'iteration']}\")\n",
    "    \n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = new_results.loc[0, 'hyperparameters']\n",
    "    model = LGBMRegressor(**hyperparameters)\n",
    "    \n",
    "    # Train and make predictions\n",
    "    model.fit(train_features, train_labels)\n",
    "    preds = model.predict(test_features)\n",
    "    rmse = (mean_squared_error(test_labels, preds))**0.5\n",
    "    r2score = r2_score(y_test, y_test_pred)\n",
    "    adj_r2 = 1 - (1 - r2score) * (test_features.shape[0] - 1) / (test_features.shape[0] - test_features.shape[1] - 1)\n",
    "    print(f\"RMSE from {name} on test data = {rmse:.5f}\")\n",
    "    print(f\"R2 score from {name} on test data = {r2score:.5f}\")\n",
    "    print(f\"Adjusted R2 score from {name} on test data = {adj_r2:.5f}\")\n",
    "    \n",
    "    # Create dataframe of hyperparameters\n",
    "    hyp_df = pd.DataFrame(columns=list(new_results.loc[0, 'hyperparameters'].keys()))\n",
    "    \n",
    "    # Iterate through each set of hyperparameters that were evaluted\n",
    "    for i, hyp in enumerate(new_results['hyperparameters']):\n",
    "          hyp_df = hyp_df.append(pd.DataFrame(hyp, index=[0]),\n",
    "                                 ignore_index=True)\n",
    "    \n",
    "    # Put the iteration and score in the hyperparameter dataframe\n",
    "    hyp_df['iteration'] = new_results['iteration']\n",
    "    hyp_df['score'] = new_results['score']\n",
    "    \n",
    "    return hyp_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:29:36.636583Z",
     "start_time": "2019-08-16T12:27:47.372662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The higest cross validation score from Bayesian was 0.38247 found on iteration 1\n",
      "RMSE from Bayesian on test data = 0.38229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>device</th>\n",
       "      <th>gpu_device_id</th>\n",
       "      <th>gpu_platform_id</th>\n",
       "      <th>is_unbalance</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>subsample</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.624928</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>11</td>\n",
       "      <td>95</td>\n",
       "      <td>192</td>\n",
       "      <td>0.856473</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.502088</td>\n",
       "      <td>3083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.639034</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>9</td>\n",
       "      <td>370</td>\n",
       "      <td>44</td>\n",
       "      <td>0.397152</td>\n",
       "      <td>0.827967</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.844486</td>\n",
       "      <td>6001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.901861</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013189</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>154</td>\n",
       "      <td>0.504199</td>\n",
       "      <td>0.040143</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.836686</td>\n",
       "      <td>10000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.393371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.921651</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>11</td>\n",
       "      <td>480</td>\n",
       "      <td>172</td>\n",
       "      <td>0.444405</td>\n",
       "      <td>0.453573</td>\n",
       "      <td>260000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.519208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.744739</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.228496</td>\n",
       "      <td>6</td>\n",
       "      <td>405</td>\n",
       "      <td>228</td>\n",
       "      <td>0.761490</td>\n",
       "      <td>0.075930</td>\n",
       "      <td>280000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.524774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting_type  colsample_bytree device gpu_device_id gpu_platform_id  \\\n",
       "0          gbdt          0.624928    gpu             0               0   \n",
       "1          gbdt          0.639034    gpu             0               0   \n",
       "2          dart          0.901861    gpu             0               0   \n",
       "3          goss          0.921651    gpu             0               0   \n",
       "4          goss          0.744739    gpu             0               0   \n",
       "\n",
       "  is_unbalance  learning_rate max_depth min_child_samples num_leaves  \\\n",
       "0         True       0.014147        11                95        192   \n",
       "1         True       0.016261         9               370         44   \n",
       "2        False       0.013189        10               180        154   \n",
       "3         True       0.019961        11               480        172   \n",
       "4         True       0.228496         6               405        228   \n",
       "\n",
       "   reg_alpha  reg_lambda subsample_for_bin  subsample n_estimators  iteration  \\\n",
       "0   0.856473    0.177063             40000   0.502088         3083          1   \n",
       "1   0.397152    0.827967            200000   0.844486         6001          5   \n",
       "2   0.504199    0.040143            160000   0.836686        10000          4   \n",
       "3   0.444405    0.453573            260000   1.000000           50          2   \n",
       "4   0.761490    0.075930            280000   1.000000            4          3   \n",
       "\n",
       "      score  \n",
       "0  0.382470  \n",
       "1  0.387753  \n",
       "2  0.393371  \n",
       "3  0.519208  \n",
       "4  0.524774  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_results = evaluate(results, name = 'Bayesian')\n",
    "bayes_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:31:40.935442Z",
     "start_time": "2019-08-16T12:31:40.930562Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save the trial results\n",
    "with open('trials.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T05:12:37.812482Z",
     "start_time": "2019-08-16T12:32:09.502688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                  | 2/195 [00:31<57:29, 17.87s/it, best loss: 0.3824701385023954]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\DL\\lib\\site-packages\\lightgbm\\callback.py:189: UserWarning: Early stopping is not available in dart mode\n",
      "  warnings.warn('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 195/195 [40:40:28<00:00, 954.61s/it, best loss: 0.37978765352778115]\n"
     ]
    }
   ],
   "source": [
    "MAX_EVALS = 200\n",
    "\n",
    "# continue training\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, trials=trials,\n",
    "            max_evals=MAX_EVALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T09:36:15.479873Z",
     "start_time": "2019-08-18T09:36:15.438881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 0,\n",
       " 'colsample_by_tree': 0.6887767729856713,\n",
       " 'gbdt_subsample': 0.7418124791090016,\n",
       " 'is_unbalance': 0,\n",
       " 'learning_rate': 0.022964491720552586,\n",
       " 'max_depth': 12.0,\n",
       " 'min_child_samples': 20.0,\n",
       " 'num_leaves': 172.0,\n",
       " 'reg_alpha': 0.13480090927812335,\n",
       " 'reg_lambda': 0.17660742377521615,\n",
       " 'subsample_for_bin': 140000.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T09:50:48.983635Z",
     "start_time": "2019-08-18T09:50:48.974867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.37978765352778115,\n",
       "  'hyperparameters': {'boosting_type': 'gbdt',\n",
       "   'colsample_bytree': 0.6887767729856713,\n",
       "   'device': 'gpu',\n",
       "   'gpu_device_id': 0,\n",
       "   'gpu_platform_id': 0,\n",
       "   'is_unbalance': True,\n",
       "   'learning_rate': 0.022964491720552586,\n",
       "   'max_depth': 12,\n",
       "   'min_child_samples': 20,\n",
       "   'num_leaves': 172,\n",
       "   'reg_alpha': 0.13480090927812335,\n",
       "   'reg_lambda': 0.17660742377521615,\n",
       "   'subsample_for_bin': 140000,\n",
       "   'subsample': 0.7418124791090016,\n",
       "   'n_estimators': 1932},\n",
       "  'iteration': 180,\n",
       "  'train_time': 439.9250337940175,\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the trials with lowest loss first\n",
    "trials_dict = sorted(trials.results, key=lambda x: x['loss'])\n",
    "trials_dict[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T10:24:39.221327Z",
     "start_time": "2019-08-18T10:22:30.689931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The higest cross validation score from BayesianFinal was 0.37979 found on iteration 180\n",
      "RMSE from BayesianFinal on test data = 0.37856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>device</th>\n",
       "      <th>gpu_device_id</th>\n",
       "      <th>gpu_platform_id</th>\n",
       "      <th>is_unbalance</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>subsample</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.688777</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>172</td>\n",
       "      <td>0.134801</td>\n",
       "      <td>0.176607</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.741812</td>\n",
       "      <td>1932</td>\n",
       "      <td>180</td>\n",
       "      <td>0.379788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010406</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>126</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.199557</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.759393</td>\n",
       "      <td>5010</td>\n",
       "      <td>187</td>\n",
       "      <td>0.379794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.709935</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>176</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.628375</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.573056</td>\n",
       "      <td>2945</td>\n",
       "      <td>97</td>\n",
       "      <td>0.379851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.663841</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>136</td>\n",
       "      <td>0.308155</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.746613</td>\n",
       "      <td>1969</td>\n",
       "      <td>150</td>\n",
       "      <td>0.379930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.768120</td>\n",
       "      <td>gpu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>0.056426</td>\n",
       "      <td>0.096521</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.784463</td>\n",
       "      <td>4835</td>\n",
       "      <td>189</td>\n",
       "      <td>0.380070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting_type  colsample_bytree device gpu_device_id gpu_platform_id  \\\n",
       "0          gbdt          0.688777    gpu             0               0   \n",
       "1          gbdt          0.733720    gpu             0               0   \n",
       "2          gbdt          0.709935    gpu             0               0   \n",
       "3          gbdt          0.663841    gpu             0               0   \n",
       "4          gbdt          0.768120    gpu             0               0   \n",
       "\n",
       "  is_unbalance  learning_rate max_depth min_child_samples num_leaves  \\\n",
       "0         True       0.022964        12                20        172   \n",
       "1         True       0.010406        12                25        126   \n",
       "2        False       0.014351        12                20        176   \n",
       "3         True       0.021814        12                20        136   \n",
       "4         True       0.010723        12                20        128   \n",
       "\n",
       "   reg_alpha  reg_lambda subsample_for_bin  subsample n_estimators  iteration  \\\n",
       "0   0.134801    0.176607            140000   0.741812         1932        180   \n",
       "1   0.095890    0.199557            120000   0.759393         5010        187   \n",
       "2   0.219238    0.628375            140000   0.573056         2945         97   \n",
       "3   0.308155    0.597981            160000   0.746613         1969        150   \n",
       "4   0.056426    0.096521            120000   0.784463         4835        189   \n",
       "\n",
       "      score  \n",
       "0  0.379788  \n",
       "1  0.379794  \n",
       "2  0.379851  \n",
       "3  0.379930  \n",
       "4  0.380070  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_FILE = 'bayes_test.csv'\n",
    "results = pd.read_csv(OUT_FILE)\n",
    "bayes_results = evaluate(results, name = 'BayesianFinal')\n",
    "bayes_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T10:24:56.611026Z",
     "start_time": "2019-08-18T10:24:56.607123Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = LGBMRegressor(random_state=50)\n",
    "\n",
    "# Training set\n",
    "train_set = lgb.Dataset(train_features, label = train_labels, categorical_feature=category_columns)\n",
    "test_set = lgb.Dataset(test_features, label = test_labels, categorical_feature=category_columns)\n",
    "\n",
    "find_model_params = trials_dict[0]['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T10:34:05.362162Z",
     "start_time": "2019-08-18T10:25:13.149393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\DL\\lib\\site-packages\\lightgbm\\engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# Perform cross validation with early stopping\n",
    "cv_results = lgb.cv(find_model_params, train_set,  num_boost_round = 10000, nfold = N_FOLDS, metrics = 'rmse', \n",
    "                    early_stopping_rounds = 100, verbose_eval = False, seed = 42, categorical_feature=category_columns,\n",
    "                    stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of esimators found in cv\n",
    "\n",
    "\n",
    "# Train and make predicions with model\n",
    "model.fit(train_features, train_labels)\n",
    "preds = model.predict(test_features)\n",
    "baseline_rmse = (mean_squared_error(test_labels, preds))**0.5\n",
    "r2score = r2_score(test_labels, preds)\n",
    "\n",
    "print(f'The baseline model has rmse {baseline_rmse:.5f} and r2score {r2score:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
